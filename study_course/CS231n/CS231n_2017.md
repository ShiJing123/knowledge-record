# CS231n: Convolutional Neural Networks for Visual Recognition Spring 2017 

### [Course Link](http://cs231n.stanford.edu/)
### [Schedule and Syllabus](http://cs231n.stanford.edu/syllabus.html)

### [Assignments2017](https://github.com/cs231n/cs231n.github.io/tree/master/assignments/2017)

## My Learning Schedule

### Lecture 1 Course Introduction 

- Computer vision overview
- Historical context
- Course logitics

### Lecture 2 [Image classification](https://www.youtube.com/watch?v=OoUX-nOEjG0&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&t=1041)
	
- Linear classfier

###	Lecture 3 [Loss Functions and Optimization](https://www.youtube.com/watch?v=h7iBpEHGVNc&index=3&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)

- Multiclass SVM loss (Hinge loss)
> 个人理解：Hinge loss 关注不但要求样本的正确类别的score大于其它类别，同时要求大于某一间隔。对于softmax，loss只是要求正确别的score高于其他类别即可。
- Softmax 
> 我们经常会使用很小的随机数初始化参数W,此时的W往往都近似为0，这是的交叉熵loss 应该为-log(1/C)=log(C), C表示类别数。因此，检查模型初始的迭代loss是否接近log(C).debug算法的正确性 trick。
