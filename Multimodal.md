# Recommended Papers ![Maintenance](https://img.shields.io/maintenance/yes/2017.svg) [![DUB](https://img.shields.io/dub/l/vibe-d.svg)](LICENSE)
- The goal of this document is to provide a reading list in Multimodal learning.


## Topics
- [Image Captioning](#image-captioning)
- [Others](#others)


## Papers
Paper list.

## Image Captioning
|No.  |Figure   |Title   |Authors  |Pub.  |Links|Datasets|
|-----|:-----:|:-----:|:-----:|:-----:|:---:|:---:|
|1|![MDF](paper_image/Jointly-Learning-Energy-Expenditures-and-Activities-using-Egocentric-Multimoda.png)|__Jointly Learning Energy Expenditures and Activities using Egocentric Multimoda__|Cesc Chunseong Park, Byeongchang Kim and Gunhee Kim|__CVPR 2017__|[PDF](https://arxiv.org/abs/1704.06485) [code](https://github.com/cesc-park/attend2u)|[IntaPIC-1.1M Json](https://drive.google.com/uc?export=download&id=0B3xszfcsfVUBdG0tU3BOQWV0a0E) [IntaPIC-1.1M Image](https://drive.google.com/uc?export=download&id=0B3xszfcsfVUBVkZGU2oxYVl6aDA])|
|2|![MDF](paper_image/Dense-Captioning-Events-in-Videos.png)|__Dense-Captioning Events in Videos__|Ranjay Krishna, Kenji Hata, Frederic Ren, Li Fei-Fei, Juan Carlos Niebles|__CVPR 2017__|[PDF](https://arxiv.org/abs/1705.00754) [Project](http://cs.stanford.edu/people/ranjaykrishna/densevid/)|[ActivityNet Captions](http://cs.stanford.edu/people/ranjaykrishna/densevid/captions.zip)|



## Others
|No.  |Figure   |Title   |Authors  |Pub.  |Links|
|-----|:-----:|:-----:|:-----:|:-----:|:---:|
|1|![MDF](image/MDF.png)|__Attend to You: Personalized Image Captioning with Context Sequence Memory Networks__|Nakamura, Katsuyuki; Yeung, Serena; Alahi, Alexandre; [Fei-Fei, Li](http://vision.stanford.edu/publications.html#year2017)|__CVPR 2017__|[PDF](http://vision.stanford.edu/pdf/nakamura2017cvpr.pdf) [Project]()|
