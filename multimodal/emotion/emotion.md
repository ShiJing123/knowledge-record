# Recommended Papers ![Maintenance](https://img.shields.io/maintenance/yes/2017.svg) [![DUB](https://img.shields.io/dub/l/vibe-d.svg)](LICENSE)
## [Home](../README.md)
- The goal of this document is to provide a reading list in Emotion.

## Topics
- [paper](#paper)
- [datasets](#datasets)
- challenge(#challenge)


## paper

### 2017
|No.  |Figure   |Title   |Authors  |Pub.  |Links|Datasets|
|-----|:-----:|:-----:|:-----:|:-----:|:---:|:---:|
|1|![Smile](paper_image/Deep_Bimodal_Regression_of_Apparent_Personality_Traits_from_Short_Video_Sequences.png)|__Deep Bimodal Regression of Apparent Personality Traits from Short Video Sequences__|[Xiu-Shen Wei](http://210.28.132.67/weixs/?AspxAutoDetectCookieSupport=1), [Chen-Lin Zhang](http://210.28.132.67/zhangcl/), [Hao Zhang](http://210.28.132.67/zhangh/), and [Jianxin Wu](https://cs.nju.edu.cn/wujx/) |__IEEE Transactions on Affective Computing 2017__|[PDF](http://lamda.nju.edu.cn/weixs/publication/tac17.pdf) [Projeact](http://lamda.nju.edu.cn/weixs/project/APA/APA.html)||

|Name  | link  | 
|-----|:-----:|
|Deep spatio-temporal features for multimodal emotion recognition| [paper](https://eprints.qut.edu.au/105854/1/292.pdf)|
|CNN BASED MUSIC EMOTION CLASSIFICATION| [paper](https://arxiv.org/pdf/1704.05665.pdf)|
|Joint Image Emotion Classification and Distribution Learning via Deep Convolutional Neural Network| [paper](https://www.ijcai.org/proceedings/2017/0456.pdf)|
|Frame-Transformer Emotion Classification Network| [paper](http://www.yugangjiang.info/publication/icmr17-emotion.pdf)|
|Recognizing Facial Expressions Using Deep Learning| [paper](http://cs231n.stanford.edu/reports/2017/pdfs/224.pdf)|
|A __review__ of affective computing: From unimodal analysis to multimodal fusion| [paper](https://ac.els-cdn.com/S1566253517300738/1-s2.0-S1566253517300738-main.pdf?_tid=c0b44872-df48-11e7-b6cc-00000aacb35e&acdnat=1513089102_a68b14a2aa580108d3276be8ac855c43)|

### 2016
|Name  | link  | 
|-----|:-----:|
|Fusing audio, visual and textual clues for sentiment analysis from multimodal content| [paper](https://ac.els-cdn.com/S0925231215011297/1-s2.0-S0925231215011297-main.pdf?_tid=8d10b112-df49-11e7-93da-00000aacb361&acdnat=1513089445_855a03b9a23456f6502325eaee761b07)|

### 2015
|Name  | link  | 
|-----|:-----:|
|Emotion Classification on face images - CS229 - Stanford University| [paper](http://cs229.stanford.edu/proj2015/158_report.pdf)|

### 2014
|Name  | link  | 
|-----|:-----:|
| __Survey__ on audiovisual emotion recognition: databases, features, and data fusion strategies| [paper](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/5BA206CFFEC3BAE321842B8EB820E179/S2048770314000110a.pdf/survey_on_audiovisual_emotion_recognition_databases_features_and_data_fusion_strategies.pdf)|
|Speech Emotion Recognition Using Deep Neural Network and Extreme Learning Machine| [paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/IS140441.pdf)|

### 2010
|Name  | link  | 
|-----|:-----:|
|A 3-D Audio-Visual Corpus of Affective Communication| [paper](http://www.fanelli.li/pubs/corpus.pdf)|

### 2008
|Name  | link  | 
|-----|:-----:|
|Emotion Recognition Based on Physiological Changes in Music Listening|[paper](https://www.informatik.uniaugsburg.de/lehrstuehle/hcm/publications/2008-TPAMI/TPAMI-0874-1206_optimized.pdf)|


## Datasets
|Name  |Year   |pdf   | 
|-----|:-----:|:-----:|
|[RML]|2008|Recognizing human emotional state from audiovisual signals|
|[IEMOCAP](http://sail.usc.edu/iemocap/iemocap_release.htm)|2008|“IEMOCAP: Interactive emotional dyadic motion capture database|
|[eNTERFACE](http://www.enterface.net/results/)|2006|The eNTERFACE05 Audio-Visual Emotion Database|
|[RECOLA](https://diuf.unifr.ch/diva/recola/annemo.html)|2013||



## Challenge
AVEC 2012 –
[The Continuous Audio/Visual Emotion Challenge](http://www.cs.nott.ac.uk/~pszmv/Documents/avec2012_preprint.pdf)



