# Recommended Papers ![Maintenance](https://img.shields.io/maintenance/yes/2017.svg) [![DUB](https://img.shields.io/dub/l/vibe-d.svg)](LICENSE)
## [Home](../../README.md)
- The goal of this document is to provide a reading list in Emotion.

## Topics
- [paper](#paper)
- [datasets](#datasets)
- [code](#code)
- [challenge](#challenge)


## paper
[2017](#2017) [2016](#2016) [2015](#2015) [2014](#2014) [2013](#2013) [2012](#2012) [2011](#2011) [2010](#2010) [2009](#2009) [2008](#2008)
### 2017

|Id|Name  | link  | Pub.|
|-----|:-----:|:-----:|:-----:|
|1|__Deep Bimodal Regression of Apparent Personality Traits from Short Video Sequences__|[paper](http://lamda.nju.edu.cn/weixs/publication/tac17.pdf) [project](http://lamda.nju.edu.cn/weixs/project/APA/APA.html)| __IEEE Transactions on Affective Computing 2017__|
|2|Deep spatio-temporal features for multimodal emotion recognition| [paper](https://eprints.qut.edu.au/105854/1/292.pdf)| 
|3|CNN Based Music Emotion Classification| [paper](https://arxiv.org/pdf/1704.05665.pdf)| |
|4|Joint Image Emotion Classification and Distribution Learning via Deep Convolutional Neural Network| [paper](https://www.ijcai.org/proceedings/2017/0456.pdf)| |
|5|Frame-Transformer Emotion Classification Network| [paper](http://www.yugangjiang.info/publication/icmr17-emotion.pdf)| |
|6|Recognizing Facial Expressions Using Deep Learning| [paper](http://cs231n.stanford.edu/reports/2017/pdfs/224.pdf)| |
|7|A __review__ of affective computing: From unimodal analysis to multimodal fusion| [paper](https://ac.els-cdn.com/S1566253517300738/1-s2.0-S1566253517300738-main.pdf?_tid=c0b44872-df48-11e7-b6cc-00000aacb35e&acdnat=1513089102_a68b14a2aa580108d3276be8ac855c43)| __Information Fusion 2017__ |
|8|Benchmarking Multimodal Sentiment Analysis| [paper](https://arxiv.org/pdf/1707.09538.pdf)| __Accepted in CICLing 2017__ |


### 2016
|Id|Name  | link  | Pub.|
|-----|:-----:|:-----:|:-----:|
|1|Fusing audio, visual and textual clues for sentiment analysis from multimodal content| [paper](https://ac.els-cdn.com/S0925231215011297/1-s2.0-S0925231215011297-main.pdf?_tid=8d10b112-df49-11e7-93da-00000aacb361&acdnat=1513089445_855a03b9a23456f6502325eaee761b07)| __Neurocomputing 2016__ |


[文字卷积](http://www.cips-cl.org/static/anthology/CCL-2017/CCL-17-058.pdf)
### 2015
|Id|Name  | link  | Pub.|
|-----|:-----:|:-----:|:-----:|
|1|Emotion Classification on face images - CS229 - Stanford University| [paper](http://cs229.stanford.edu/proj2015/158_report.pdf)| |
|2.|Deep Multimodal Learning for Affective Analysis and Retrieval|[paper](http://ieeexplore.ieee.org.eproxy1.lib.hku.hk/document/7277066/?reload=true)|IEEE transiactions on multimedia|
|3.|Multimodal convolutional neural networks for matching image and sentence|[paper](https://arxiv.org/abs/1504.06063)|ICCV|



### 2014
|Id|Name  | link  | Pub.|
|-----|:-----:|:-----:|:-----:|
|1| __Survey__ on audiovisual emotion recognition: databases, features, and data fusion strategies| [paper](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/5BA206CFFEC3BAE321842B8EB820E179/S2048770314000110a.pdf/survey_on_audiovisual_emotion_recognition_databases_features_and_data_fusion_strategies.pdf)| |
|2|Speech Emotion Recognition Using Deep Neural Network and Extreme Learning Machine| [paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/IS140441.pdf)| |
|3|A new approach of audio emotion recognition|[paper](https://ac.els-cdn.com/S0957417414001638/1-s2.0-S0957417414001638-main.pdf?_tid=78f379a6-efb8-11e7-a8c0-00000aab0f02&acdnat=1514896305_940f723e8801f9354cefed112a59e667)|Expert Systems with Applications|

### 2010
|Id|Name  | link  | Pub.|
|-----|:-----:|:-----:|:-----:|
|1|A 3-D Audio-Visual Corpus of Affective Communication| [paper](http://www.fanelli.li/pubs/corpus.pdf)| |

### 2008
|Id|Name  | link  | Pub.|
|-----|:-----:|:-----:|:-----:|
|1|Emotion Recognition Based on Physiological Changes in Music Listening|[paper](https://www.informatik.uniaugsburg.de/lehrstuehle/hcm/publications/2008-TPAMI/TPAMI-0874-1206_optimized.pdf)| |


## Datasets
|Name  |Year   |pdf   | 
|-----|:-----:|:-----:|
|RML|2008|Recognizing human emotional state from audiovisual signals|
|[IEMOCAP](http://sail.usc.edu/iemocap/iemocap_release.htm)|2008|“IEMOCAP: Interactive emotional dyadic motion capture database|
|[eNTERFACE](http://www.enterface.net/results/)|2006|The eNTERFACE05 Audio-Visual Emotion Database|
|[RECOLA](https://diuf.unifr.ch/diva/recola/annemo.html)|2013||


## Code
- [face_recognition](https://github.com/ageitgey/face_recognition)

## Challenge
AVEC 2012 –
[The Continuous Audio/Visual Emotion Challenge](http://www.cs.nott.ac.uk/~pszmv/Documents/avec2012_preprint.pdf)



