# Recommended Papers ![Maintenance](https://img.shields.io/maintenance/yes/2017.svg) [![DUB](https://img.shields.io/dub/l/vibe-d.svg)](LICENSE)
- The goal of this document is to provide a reading list in Multimodal learning.


## Topics
- [Image Captioning](#image-captioning)
- [Others](#others)


## Papers
Paper list.

## Image Captioning
|No.  |Figure   |Title   |Authors  |Pub.  |Links|
|-----|:-----:|:-----:|:-----:|:-----:|:---:|
|1|![MDF](image/MDF.png)|__Jointly Learning Energy Expenditures and Activities using Egocentric Multimoda__|Cesc Chunseong Park, Byeongchang Kim and Gunhee Kim|__CVPR 2017__|[PDF](https://arxiv.org/abs/1704.06485) [Project](https://github.com/cesc-park/attend2u)|

## Others
|No.  |Figure   |Title   |Authors  |Pub.  |Links|
|-----|:-----:|:-----:|:-----:|:-----:|:---:|
|1|![MDF](image/MDF.png)|__Attend to You: Personalized Image Captioning with Context Sequence Memory Networks__|Nakamura, Katsuyuki; Yeung, Serena; Alahi, Alexandre; [Fei-Fei, Li](http://vision.stanford.edu/publications.html#year2017)|__CVPR 2017__|[PDF](http://vision.stanford.edu/pdf/nakamura2017cvpr.pdf) [Project]()|
